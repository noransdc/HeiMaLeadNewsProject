# Kafka / Streams / Redis 热榜链路设计与认知复盘



> **背景一句话版**
>  我在项目中实现了一条完整的用户行为热榜链路，从事实事件采集，到实时派生统计，再到 Redis 展示，过程中完整踩过 Kafka Streams 的时间语义、重放、幂等和一致性边界问题。

------

## 一、先说整体架构，而不是上来讲技术点

我一开始就把系统分成了三层，而不是把所有逻辑堆在一条链路里：

```
事实层（Kafka）
  → 沉淀层（普通 Consumer + DB）
  → 派生层（Kafka Streams + Redis）
```

### 1️⃣ 事实层：Kafka 只做一件事——记录“发生过什么”

- 所有用户行为（浏览、点赞、收藏）都写入一个统一 topic
- 每条事件都有：
  - eventId（幂等用）
  - articleId
  - eventType
  - eventTime（业务发生时间）

Kafka 在这里的角色非常明确：

> **Kafka 是事实日志，不是流程队列，也不是统计结果。**

------

## 二、为什么要保留“普通 Consumer”，而不是只用 Streams？

这是我一开始就刻意做的区分。

### 普通 Consumer 的职责

- 消费同一份事实事件
- 用 eventId 做幂等裁决
- 更新数据库里的 `article_interaction` 表
- 作为**长期正确性和数据恢复的兜底**

它的定位是：

> **不在实时主链路上，但在系统“能不能兜底、能不能重算”这件事上不可或缺。**

------

## 三、Kafka Streams 的真实角色：不是事实，而是“派生视角”

### 我一开始用 Streams 做的事情

- 按 articleId 分组
- 基于 event-time 做窗口聚合
- 计算一定时间窗口内的行为增量
- 输出聚合结果，用来驱动热榜

关键是，我在设计时就明确了一点：

> **Streams 的输出不是事实，只是派生结果。**

这直接影响了后面的所有决策。

------

## 四、我在 Streams 里踩到的第一个“关键坑”：event-time

### 1️⃣ 不显式指定 TimestampExtractor 的问题

一开始我没有加 TimestampExtractor，Streams 默认用 Kafka 写入时间：

- 窗口是按 ingestion-time 划的
- 看起来“能跑”，但语义是错的

后来我引入了自定义 TimestampExtractor，用事件里的 `eventTime`。

### 2️⃣ 真正的坑在这里

我是在**已经跑过一段数据之后**才加的 Extractor。

结果：

- 重启 Streams
- 重放历史数据
- 同一条事件被用 **不同时间语义** 重新解释
- 窗口归属变化，聚合结果翻倍

这让我真正意识到一句话：

> **event-time ≈ 数据模型，不是配置参数。**

工程结论是：

> **一旦 Streams 应用上线，时间语义不可修改；
>  改语义的唯一方式是：新 application.id + 全量重算。**

------

## 五、第二个关键认知：Streams 的 state 是“结果”，不是“缓存”

当我看到重启后计数变成 2 时，我一开始以为是 Kafka 重复消费。

后来验证发现：

- 上游事件只有 1 条
- 普通 Consumer 里是正确的
- Streams 的 state 因为 at-least-once + 语义变更被污染

这一步让我彻底想清楚：

> **Streams 的 state 不是事实数据，
>  而是在某套语义下算出来的结果。**

所以工程策略应该是：

- state 错了 → 不修
- 直接 **换 application.id 重算**

这也是为什么线上不能“随便删 state”，而是用新 id 双跑切换。

------

## 六、关于 exactly-once：我最后的判断

我专门验证过：

- 不开 EOS，在异常重启时，Streams 确实可能重复计算
- 开了 EOS，可以保证：
  - state 更新
  - changelog 写入
  - offset 提交
     三者事务一致

但我最终的判断是：

> **是否开启 exactly-once，不是技术好坏问题，而是业务代价问题。**

在我的场景里：

- 热榜 / 行为趋势
- Redis 覆盖写
- 定时裁剪兜底
- 少量重复可接受

所以我选择：

> **不开 EOS，但明确 Streams 不是事实源。**

如果是计费 / 结算类场景，我会毫不犹豫开启 EOS。

------

## 七、Redis 这一层，我刻意做了一个关键设计

### 写路径和删路径完全分离

- Streams / Consumer 下游：
  - **只做 ZADD**
- 定时任务：
  - 统一裁剪 TopN

这样做的目的不是性能，而是并发安全：

> **避免“边写边删”导致排行榜抖动和误删。**

同时我也明确：

> **Redis 不是事实源，只是展示投影，
>  可以丢、可以重算、可以覆盖。**

------

## 八、最终，我对这条链路的“成熟认知”

如果让我总结这条链路里最重要的 5 个认知，会是这几句：

1. Kafka 是事实日志，不是统计结果
2. Streams 的 state 是结果，错了就重算
3. event-time 是语义，不是参数
4. exactly-once 是异常语义保障，不是必选项
5. Redis 只做展示投影，不承担正确性

------

## 九、如果面试官问：你最大的收获是什么？

我会这样回答：

> **不是学会了 Kafka Streams 的 API，
>  而是学会了给“事实、派生、展示”划清边界。**
>
> 知道哪些地方必须 100% 正确，
>  哪些地方可以近似、可重算、可兜底。

------

### 结尾一句（很加分）

> 这条链路现在业务是稳定跑起来的，但更重要的是：
>  **如果半年后要升级语义、换策略、甚至推倒重来，我知道该从哪里下手。**
