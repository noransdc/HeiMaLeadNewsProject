# 热门文章统计 —— 可靠事件链路设计（不含 Redis）





## 1. 背景与问题

在内容类系统中，**文章的浏览、点赞、评论、收藏等行为非常高频**，同时又存在以下挑战：

1. 用户行为请求量大、并发高
2. 系统采用 Kafka 进行异步解耦，**消息可能重复投递（重放）**
3. 热度统计属于**派生数据**，不要求强一致，但要求系统稳定
4. 不能因为单条异常数据，导致整个消费链路阻塞

因此，本模块的目标是：

> **在保证系统可用性和可扩展性的前提下，
>  可靠地统计文章行为数据，并为后续热门文章计算提供基础。**

------

## 2. 整体设计思路

整体采用 **“事实层 + 派生层”** 的分层设计思想：

- **事实层（Fact Layer）**：
   用户行为事件是否发生，只记录一次，不可回滚
- **派生层（Derived Layer）**：
   行为统计结果，允许延迟、允许丢失、允许重算

核心原则是：

> **事实强一致，派生最终一致**

------

## 3. 系统整体流程

### 3.1 事件产生（user-service）

1. 用户在前端触发行为（点赞 / 收藏 / 评论等）
2. user-service 在本地事务中：
   - 写入业务表（如 user_collection）
   - 写入 `event_outbox` 事件表

`event_outbox` 中包含：

- `event_id`（全局唯一）
- `event_type`（行为类型）
- `aggregate_type / aggregate_id`（领域对象）
- `payload`（事件数据）

该步骤采用 **Outbox 模式**，保证：

> **数据库写入成功的事件，一定会被投递到 Kafka**

------

### 3.2 事件投递（Outbox → Kafka）

由定时任务或后台线程：

1. 扫描 `event_outbox` 中未发送事件
2. 将事件发送到 Kafka
3. 标记事件为已发送

Kafka topic 示例：

```
article.behavior.event
```

------

### 3.3 事件消费（article-service 普通消费者）

article-service 作为 **普通 Kafka Consumer**，负责：

- 幂等裁决
- 派生计数更新

消费流程如下：

```
Kafka 消息
→ article_event_consumed（幂等表）
→ article_interaction（派生计数）
```

------

## 4. 幂等设计（关键）

### 4.1 幂等表：article_event_consumed

设计一张幂等消费表：

```
article_event_consumed (
  event_id     PK,
  event_type,
  article_id,
  create_time
)
```

规则：

- `event_id` 作为主键
- **Kafka 重放时，重复事件会触发唯一键冲突**

### 4.2 幂等消费逻辑

```
try {
    save(articleEventConsumed);
} catch (DuplicateKeyException e) {
    // 说明事件已被处理过，直接忽略
    return false;
}
```

这样可以保证：

- Kafka 重放不会导致重复统计
- 系统天然支持 **at-least-once 投递语义**

------

## 5. 派生计数设计（article_interaction）

### 5.1 派生表定位

`article_interaction` 用于存储：

- view_count
- like_count
- comment_count
- collect_count

它的特点是：

- 非事实数据
- 可重算
- 可补偿
- 不作为强一致业务依据

------

### 5.2 并发安全更新策略

**禁止使用：**

```
select → Java 计算 → update
```

原因：并发下会丢数据。

采用 **原子 SQL 更新**：

```
update article_interaction
set like_count = like_count + 1
where article_id = ?
```

------

### 5.3 数据不存在的处理

如果文章第一次收到行为事件：

- update 影响行数 = 0
- 说明该文章还没有 interaction 记录

采用以下兜底策略：

```
int rows = update();
if (rows == 0) {
    try {
        insertInit();  // 插入初始计数
    } catch (DuplicateKeyException e) {
        // 并发下可能已被插入，忽略
    }
    update(); // 再次更新
}
```

保证：

- 并发安全
- 不抛异常
- 不阻塞消费

------

## 6. 异常与 Kafka 重放策略

### 6.1 异常分类原则

判断是否让 Kafka 重放，只取决于一件事：

> **该异常是否“稍后重试有成功可能”**

------

### 6.2 允许 Kafka 重放的异常（系统异常）

- 数据库连接异常
- SQL 执行异常
- 网络异常

处理方式：

- 不 catch
- 抛出异常
- 回滚事务
- Kafka 自动重放

------

### 6.3 不允许 Kafka 重放的异常（数据异常）

- eventType 解析失败
- 参数非法
- 重复 event_id

处理方式：

- catch 异常
- 记录日志
- 正常返回
- 提交 offset

------

## 7. 为什么允许“派生不一致”

在以下场景中：

- 事件已写入 `article_event_consumed`
- 派生计数未成功更新

系统选择：

> **接受派生不一致，而不是回滚事实**

原因：

- 派生数据可重算
- 回滚会导致 Kafka 无限重试
- 系统可用性优先于绝对准确

这是消息驱动系统中的**典型工程取舍**。

------

## 8. 当前阶段的边界说明

截至目前：

- 已完成 **可靠事件链路**
- 已完成 **幂等消费**
- 已完成 **派生计数**

**尚未涉及：**

- Redis 热榜
- Kafka Streams 聚合
- 热度分值计算

这些属于 **性能与读优化阶段**，不影响系统正确性。

------

## 9. 总结

本模块通过：

- Outbox 模式
- Kafka 幂等消费
- 原子 SQL 派生更新
- 明确的异常与重放策略

构建了一条：

> **不会因重复消息或异常数据而失效的文章行为统计链路**

为后续的热门文章计算和 Redis 缓存优化，提供了可靠的数据基础。
