# HeiMaLeadNewsProject







用户收藏行为产生的是用户与文章的事实关联关系，该事实由 user 服务持有并落库。
 文章收藏计数属于基于该事实的派生数据，不应在同一请求链路中同步写入，而应通过 user 服务发布领域事件，由 article 服务异步消费生成，从而实现解耦和最终一致性。



**DDD** 是 **Domain-Driven Design（领域驱动设计）**。



user-service 负责事实落库并生成唯一事件；
 article-core 通过事件去重表保证幂等，在同一事务中完成“去重记录 + 派生更新”；
 front 不参与任何双写或一致性控制。

### 1️⃣ MQ 发送失败怎么办？

- outbox 表是**兜底**
- 定时任务扫描未发送事件
- 重试发送

这是 **Transactional Outbox 的标准配套**



### 2️⃣ 取消收藏怎么做？

- user-service：
  - 删除 user_collection
  - 发 `ArticleUnCollectedEvent`
- article-core：
  - 单独的 eventId
  - consume_log 仍然生效
  - `collection_count -1`

不能复用原事件。



### 3️⃣ consume_log 会不会无限增长？

会。

解决方案：

- 按时间归档
- 按事件类型拆表
- 或只保留 N 天（统计已固化）



系统采用事件驱动架构，用户行为事实由 user 服务通过事务消息表保证一次性产生；
 派生统计通过 Kafka Streams 进行高吞吐计算；
 最终在文章服务侧通过事件消费日志保证幂等，从而在保证正确性的前提下提升统计性能。







### 覆盖 Redis 的“核心数据结构”

仅靠热门文章，你就能自然用到：

| 需求     | Redis 结构 |
| -------- | ---------- |
| 热度排序 | ZSET       |
| TopN     | ZREVRANGE  |
| 分值更新 | ZINCRBY    |
| 过期     | EXPIRE     |
| 兜底     | GET / SET  |

## 四、Redis 在你这个项目里的“够用清单”

### 🟢 必须掌握（写得出来）

#### 1️⃣ ZSET（重点）

你需要会：

```
ZINCRBY hot:article 1 articleId
ZREVRANGE hot:article 0 29 WITHSCORES
```

并且能解释：

- 为什么用 ZSET
- score 是什么
- member 是什么

------

#### 2️⃣ 缓存兜底逻辑

你需要能讲清楚：

```
1. 查 Redis
2. 没有 → 查 DB
3. 回填 Redis
```

以及：

- Redis 挂了怎么办
- 数据不准怎么办

------

#### 3️⃣ TTL / 定期刷新

- 热榜多久刷新
- 是否需要过期
- 定时任务 or Streams

------

### 🟡 了解即可（不用实现）

- 缓存穿透（知道布隆过滤器）
- 缓存雪崩（知道过期随机）
- 缓存击穿（知道互斥锁）

**只要“知道思路”，不用写代码。**

------

### 🔵 现在可以完全不碰的

- Redis Cluster
- Redis 持久化细节（RDB/AOF 参数）
- Lua 脚本
- Redis 事务

👉 **面试不要求你在项目里用这些。**



热门文章模块中使用 Redis ZSET 存储文章热度，通过异步消息更新分值，前端请求直接从 Redis 读取 TopN，数据库作为最终兜底，既减少了数据库压力，又保证了数据的最终一致性。
